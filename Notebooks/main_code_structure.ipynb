{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import time\n",
    "import langchain\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "# import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "llm = HuggingFaceHub(repo_id=model_name, model_kwargs={\"temperature\":0.9,\"max_length\":500})\n",
    "\n",
    "# Initialize the embeddings using a Hugging Face model\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "huggingface_api_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "if huggingface_api_token is None:\n",
    "    raise ValueError(\"HUGGINGFACEHUB_API_TOKEN not found. Make sure it's set in the .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(\n",
    "    urls = [\n",
    "        \"https://www.moneycontrol.com/news/business/banks/hdfc-bank-re-appoints-sanmoy-chakrabarti-as-chief-risk-officer-11259771.html\",\n",
    "        \"https://www.moneycontrol.com/news/business/markets/market-corrects-post-rbi-ups-inflation-forecast-icrr-bet-on-these-top-10-rate-sensitive-stocks-ideas-11142611.html\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiaizer LLM wth the required parameters\n",
    "llm = OpenAI(temperature = 0.9,max_tokens = 500)\n",
    "\n",
    "loaders = UnstructuredURLLoader(urls = [\n",
    "    \"https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html\",\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\"\n",
    "]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "# As data is that of type documents we can directly use split_documents over split_text to retrieve the chunks\n",
    "docs = text_splitter.split_documents(data)\n",
    "len(docs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.moneycontrol.com/news/business/banks/hdfc-bank-re-appoints-sanmoy-chakrabarti-as-chief-risk-officer-11259771.html'}, page_content='Mutual Fund\\n\\nPre-Market\\n\\nIPO\\n\\nGlobal Market\\n\\nBudget 2024\\n\\nElections 2024\\n\\nGold Rate\\n\\nBSE Sensex\\n\\nForum\\n\\nMC 30\\n\\nNews\\n\\nBusiness\\n\\nMarkets\\n\\nStocks\\n\\nIncome Tax Calculator\\n\\nElection Schedule 2024\\n\\nIndia News\\n\\nEconomy\\n\\nMutual Funds\\n\\nPersonal Finance\\n\\nIPO News\\n\\nStartups\\n\\nStocks: A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z | Others\\n\\nMutual Funds: A | B | C | D | E | F | G | H | I | J | K | L | M | N | O | P | Q | R | S | T | U | V | W | X | Y | Z\\n\\nVisit the App Store to see all our apps:\\n\\nDownload from Google PlayDownload from APP StoreDownload from Windows Phone\\n\\nTools\\n\\nRetirement Planning\\n\\nEMI Calculator\\n\\nSIP Calculator\\n\\nSIP Planner\\n\\nUseful Links\\n\\nCrypto News\\n\\nBank Holidays in India\\n\\nGold Rate Today\\n\\nSilver Rate Today\\n\\nTrending News\\n\\nStartups\\n\\nNational News\\n\\nMC Videos\\n\\nMC You Tube\\n\\nHouse Purchase Index\\n\\nBest Portfolio Manager\\n\\nSmall Savings Schemes\\n\\nBonds\\n\\nTopperLearning\\n\\nClear Study Doubts\\n\\nEducation Franchisee Opportunity\\n\\nSpecials')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:55\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create the FAISS index using the Hugging Face embeddings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vectorindex_hugging_face \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(docs, embeddings)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:852\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    850\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1042\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[1;32m-> 1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m   1043\u001b[0m     texts,\n\u001b[0;32m   1044\u001b[0m     embeddings,\n\u001b[0;32m   1045\u001b[0m     embedding,\n\u001b[0;32m   1046\u001b[0m     metadatas\u001b[38;5;241m=\u001b[39mmetadatas,\n\u001b[0;32m   1047\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1049\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:994\u001b[0m, in \u001b[0;36mFAISS.__from\u001b[1;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__from\u001b[39m(\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    993\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m--> 994\u001b[0m     faiss \u001b[38;5;241m=\u001b[39m dependable_faiss_import()\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m distance_strategy \u001b[38;5;241m==\u001b[39m DistanceStrategy\u001b[38;5;241m.\u001b[39mMAX_INNER_PRODUCT:\n\u001b[0;32m    996\u001b[0m         index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:57\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import faiss python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install faiss-gpu` (for CUDA supported GPU) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `pip install faiss-cpu` (depending on Python version).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m faiss\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version)."
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the FAISS index using the Hugging Face embeddings\n",
    "vectorindex_hugging_face = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import faiss\n",
    "texts = [doc.page_content for doc in docs]\n",
    "\n",
    "# Create the FAISS index using the Hugging Face embeddings\n",
    "vectorindex_hugging_face = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing vector index in local ##Vector database\n",
    "\n",
    "file_path = \"vector_index.pkl\"\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(vectorindex_hugging_face, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pickle file into memory\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        vectorIndex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQAWithSourcesChain(verbose=False, combine_documents_chain=MapReduceDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n{context}\\nQuestion: {question}\\nRelevant text, if any:'), llm=HuggingFaceHub(client=<InferenceClient(model='gpt2', timeout=None)>, repo_id='gpt2', task='text-generation', model_kwargs={'temperature': 0.9, 'max_length': 500}), output_parser=StrOutputParser(), llm_kwargs={}), reduce_documents_chain=ReduceDocumentsChain(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['question', 'summaries'], input_types={}, partial_variables={}, template='Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\nQUESTION: Which state/country\\'s law governs the interpretation of the contract?\\n=========\\nContent: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\\nSource: 28-pl\\nContent: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\n\\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\n\\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\\n\\n11.9 No Third-Party Beneficiaries.\\nSource: 30-pl\\nContent: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\\nSource: 4-pl\\n=========\\nFINAL ANSWER: This Agreement is governed by English law.\\nSOURCES: 28-pl\\n\\nQUESTION: What did the president say about Michael Jackson?\\n=========\\nContent: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\\nSource: 0-pl\\nContent: And we won’t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\\nSource: 24-pl\\nContent: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay.\\nSource: 5-pl\\nContent: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.\\nSource: 34-pl\\n=========\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nQUESTION: {question}\\n=========\\n{summaries}\\n=========\\nFINAL ANSWER:'), llm=HuggingFaceHub(client=<InferenceClient(model='gpt2', timeout=None)>, repo_id='gpt2', task='text-generation', model_kwargs={'temperature': 0.9, 'max_length': 500}), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content', 'source'], input_types={}, partial_variables={}, template='Content: {page_content}\\nSource: {source}'), document_variable_name='summaries')), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000243203D3E00>, search_kwargs={}))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RetrievalQAWithSourcesChain.from_llm(llm= llm,retriever = vectorIndex.as_retriever())\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khyati\\AppData\\Local\\Temp\\ipykernel_2708\\773810536.py:5: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({\"question\": query}, return_only_outputs=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is the price of tiago iCNG\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input_list\": [\n",
      "    {\n",
      "      \"context\": \"Expert: Foram Chheda, CMT, technical research analyst and founder of ChartAnalytics.co.in\\n\\nHDFC Bank: Buy | LTP: Rs 1,647 | Stop-Loss: Rs 1,612 | Target: Rs 1,720 | Return: 4.4 percent\\n\\nAfter marking a high on a closing basis in July this year, HDFC Bank's stock price saw a corrective decline and halted at Rs 1,579-1,580 levels which was in close proximity to the 200-day MA (moving average) marking it as a strong support level.\\n\\nThe price movement after that led to the development of the symmetrical triangle. Currently, the stock is very close to multiple moving average support level at 50-day, 100-day and 200-day MA which is expected to act as a strong support level and the price is likely to move towards the previous highs of Rs 1,720 levels.\\n\\nThus, one should continue to hold the stock with stop-loss of Rs 1,612 and can expect a potential up move towards Rs 1,720 levels.\\n\\nManappuram Finance: Buy | LTP: Rs 142.40 | Stop-Loss: Rs 131 | Target: Rs 155 | Return: 9 percent\",\n",
      "      \"question\": \"what is the price of tiago iCNG\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"Related stories\\n\\nBulk Deals: Morgan Stanley Asia Singapore Pte picks up 0.57% stake in Titagarh Rail Systems\\n\\nFIIs net sell Rs 3,436-crore shares, DIIs net buy shares worth Rs 2,256 crore\\n\\nVoltas, Rallis, BSE, HDFC AMC among the top gainers and losers in trade on October 16\\n\\nMeanwhile, the RBI has attempted to neutralize the liquidity impact of the Rs 2000/- notes into the banking system, and has hiked incremental CRR (cash reserve ratio) to 10 percent till September 2023 to address surplus liquidity generated by various factors.\\n\\nThe market has reacted negatively to the rising inflation forecast and incremental CRR for banks announced by the RBI. Hence the Bank Nifty fell 240 points to 44,640, while the BSE Sensex fell 246 points to 65,750, and the Nifty50 dropped 69 points to 19,564, at 12:49 hours IST.\",\n",
      "      \"question\": \"what is the price of tiago iCNG\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"Manappuram Finance: Buy | LTP: Rs 142.40 | Stop-Loss: Rs 131 | Target: Rs 155 | Return: 9 percent\\n\\nSince February 2022, Manappuram Finance has been in a consolidation phase. After reaching a low point at Rs 81 levels in June 2022, the stock gradually climbed. During its ascent, it surpassed the 50-day, 100-day, and 200-day moving averages. However, its upward momentum slowed around Rs 133-134 levels, acting as a resistance, and a corrective decline followed. This decline found support near the 200-day moving average. A rebound in the price followed this price action.\\n\\nIn the past month, the price tested the resistance at Rs 131-133 levels multiple times. Finally, a breakout occurred which took the price above the horizontal trendline resistance of Rs 133, creating fresh buying opportunities.\\n\\nPresently, one can hold the stock, maintain a stop-loss near Rs 131, while expecting an upward move towards Rs 155.\",\n",
      "      \"question\": \"what is the price of tiago iCNG\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"Hero MotoCorp: Buy | LTP: Rs 3,059.7 | Stop-Loss: Rs 2,850 | Target: Rs 3,500 | Return: 14 percent\\n\\nIn the weekly timeframe, Hero price retraced 0.618 percent from its high after an upward move. The stock found support at the EMA and rebounded, approaching the previous high. This is accompanied by a pattern of higher highs and higher lows, indicating a bullish trend.\\n\\nAdditionally, the price remains above the 100-period EMA and the Ichimoku Indicator, supporting the uptrend. The RSI momentum indicator is also trending, with new highs, confirming the trend.\\n\\nIn light of these technical factors, a long position could be considered at Rs 3,059 or a potential decline to Rs 3,050, with a target price of Rs 3,500. However, this bullish view would be invalidated if the stock closes below the support level of Rs 2,850.\\n\\nBank of Maharashtra: Buy | LTP: Rs 37.3 | Stop-Loss: Rs 30 | Target: Rs 50 | Return: 34 percent\",\n",
      "      \"question\": \"what is the price of tiago iCNG\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nExpert: Foram Chheda, CMT, technical research analyst and founder of ChartAnalytics.co.in\\n\\nHDFC Bank: Buy | LTP: Rs 1,647 | Stop-Loss: Rs 1,612 | Target: Rs 1,720 | Return: 4.4 percent\\n\\nAfter marking a high on a closing basis in July this year, HDFC Bank's stock price saw a corrective decline and halted at Rs 1,579-1,580 levels which was in close proximity to the 200-day MA (moving average) marking it as a strong support level.\\n\\nThe price movement after that led to the development of the symmetrical triangle. Currently, the stock is very close to multiple moving average support level at 50-day, 100-day and 200-day MA which is expected to act as a strong support level and the price is likely to move towards the previous highs of Rs 1,720 levels.\\n\\nThus, one should continue to hold the stock with stop-loss of Rs 1,612 and can expect a potential up move towards Rs 1,720 levels.\\n\\nManappuram Finance: Buy | LTP: Rs 142.40 | Stop-Loss: Rs 131 | Target: Rs 155 | Return: 9 percent\\nQuestion: what is the price of tiago iCNG\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nRelated stories\\n\\nBulk Deals: Morgan Stanley Asia Singapore Pte picks up 0.57% stake in Titagarh Rail Systems\\n\\nFIIs net sell Rs 3,436-crore shares, DIIs net buy shares worth Rs 2,256 crore\\n\\nVoltas, Rallis, BSE, HDFC AMC among the top gainers and losers in trade on October 16\\n\\nMeanwhile, the RBI has attempted to neutralize the liquidity impact of the Rs 2000/- notes into the banking system, and has hiked incremental CRR (cash reserve ratio) to 10 percent till September 2023 to address surplus liquidity generated by various factors.\\n\\nThe market has reacted negatively to the rising inflation forecast and incremental CRR for banks announced by the RBI. Hence the Bank Nifty fell 240 points to 44,640, while the BSE Sensex fell 246 points to 65,750, and the Nifty50 dropped 69 points to 19,564, at 12:49 hours IST.\\nQuestion: what is the price of tiago iCNG\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nManappuram Finance: Buy | LTP: Rs 142.40 | Stop-Loss: Rs 131 | Target: Rs 155 | Return: 9 percent\\n\\nSince February 2022, Manappuram Finance has been in a consolidation phase. After reaching a low point at Rs 81 levels in June 2022, the stock gradually climbed. During its ascent, it surpassed the 50-day, 100-day, and 200-day moving averages. However, its upward momentum slowed around Rs 133-134 levels, acting as a resistance, and a corrective decline followed. This decline found support near the 200-day moving average. A rebound in the price followed this price action.\\n\\nIn the past month, the price tested the resistance at Rs 131-133 levels multiple times. Finally, a breakout occurred which took the price above the horizontal trendline resistance of Rs 133, creating fresh buying opportunities.\\n\\nPresently, one can hold the stock, maintain a stop-loss near Rs 131, while expecting an upward move towards Rs 155.\\nQuestion: what is the price of tiago iCNG\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nHero MotoCorp: Buy | LTP: Rs 3,059.7 | Stop-Loss: Rs 2,850 | Target: Rs 3,500 | Return: 14 percent\\n\\nIn the weekly timeframe, Hero price retraced 0.618 percent from its high after an upward move. The stock found support at the EMA and rebounded, approaching the previous high. This is accompanied by a pattern of higher highs and higher lows, indicating a bullish trend.\\n\\nAdditionally, the price remains above the 100-period EMA and the Ichimoku Indicator, supporting the uptrend. The RSI momentum indicator is also trending, with new highs, confirming the trend.\\n\\nIn light of these technical factors, a long position could be considered at Rs 3,059 or a potential decline to Rs 3,050, with a target price of Rs 3,500. However, this bullish view would be invalidated if the stock closes below the support level of Rs 2,850.\\n\\nBank of Maharashtra: Buy | LTP: Rs 37.3 | Stop-Loss: Rs 30 | Target: Rs 50 | Return: 34 percent\\nQuestion: what is the price of tiago iCNG\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [1.11s] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError('(Request ID: 6xru6oNFwV9nGkClLB6jQ)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 406, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\requests\\\\models.py\\\", line 1024, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 779, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 1502, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_community\\\\llms\\\\huggingface_hub.py\\\", line 138, in _call\\n    response = self.client.post(\\n               ^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\inference\\\\_client.py\\\", line 305, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 460, in hf_raise_for_status\\n    raise _format(BadRequestError, message, response) from e\\n\\n\\nhuggingface_hub.errors.BadRequestError: (Request ID: 6xru6oNFwV9nGkClLB6jQ)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [1.11s] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError('(Request ID: 6xru6oNFwV9nGkClLB6jQ)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 406, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\requests\\\\models.py\\\", line 1024, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 779, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 1502, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_community\\\\llms\\\\huggingface_hub.py\\\", line 138, in _call\\n    response = self.client.post(\\n               ^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\inference\\\\_client.py\\\", line 305, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 460, in hf_raise_for_status\\n    raise _format(BadRequestError, message, response) from e\\n\\n\\nhuggingface_hub.errors.BadRequestError: (Request ID: 6xru6oNFwV9nGkClLB6jQ)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [1.11s] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError('(Request ID: 6xru6oNFwV9nGkClLB6jQ)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 406, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\requests\\\\models.py\\\", line 1024, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 779, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 1502, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_community\\\\llms\\\\huggingface_hub.py\\\", line 138, in _call\\n    response = self.client.post(\\n               ^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\inference\\\\_client.py\\\", line 305, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 460, in hf_raise_for_status\\n    raise _format(BadRequestError, message, response) from e\\n\\n\\nhuggingface_hub.errors.BadRequestError: (Request ID: 6xru6oNFwV9nGkClLB6jQ)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] [1.11s] LLM run errored with error:\n",
      "\u001b[0m\"BadRequestError('(Request ID: 6xru6oNFwV9nGkClLB6jQ)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 406, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\requests\\\\models.py\\\", line 1024, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 779, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 1502, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_community\\\\llms\\\\huggingface_hub.py\\\", line 138, in _call\\n    response = self.client.post(\\n               ^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\inference\\\\_client.py\\\", line 305, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 460, in hf_raise_for_status\\n    raise _format(BadRequestError, message, response) from e\\n\\n\\nhuggingface_hub.errors.BadRequestError: (Request ID: 6xru6oNFwV9nGkClLB6jQ)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain] [1.11s] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError('(Request ID: 6xru6oNFwV9nGkClLB6jQ)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 406, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\requests\\\\models.py\\\", line 1024, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\llm.py\\\", line 248, in apply\\n    response = self.generate(input_list, run_manager=run_manager)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 755, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 950, in generate\\n    output = self._generate_helper(\\n             ^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 792, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 779, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 1502, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_community\\\\llms\\\\huggingface_hub.py\\\", line 138, in _call\\n    response = self.client.post(\\n               ^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\inference\\\\_client.py\\\", line 305, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 460, in hf_raise_for_status\\n    raise _format(BadRequestError, message, response) from e\\n\\n\\nhuggingface_hub.errors.BadRequestError: (Request ID: 6xru6oNFwV9nGkClLB6jQ)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain] [1.12s] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError('(Request ID: 6xru6oNFwV9nGkClLB6jQ)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 406, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\requests\\\\models.py\\\", line 1024, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py\\\", line 160, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\combine_documents\\\\base.py\\\", line 138, in _call\\n    output, extra_return_dict = self.combine_docs(\\n                                ^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\combine_documents\\\\map_reduce.py\\\", line 240, in combine_docs\\n    map_results = self.llm_chain.apply(\\n                  ^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\llm.py\\\", line 251, in apply\\n    raise e\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\llm.py\\\", line 248, in apply\\n    response = self.generate(input_list, run_manager=run_manager)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 755, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 950, in generate\\n    output = self._generate_helper(\\n             ^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 792, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 779, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 1502, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_community\\\\llms\\\\huggingface_hub.py\\\", line 138, in _call\\n    response = self.client.post(\\n               ^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\inference\\\\_client.py\\\", line 305, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 460, in hf_raise_for_status\\n    raise _format(BadRequestError, message, response) from e\\n\\n\\nhuggingface_hub.errors.BadRequestError: (Request ID: 6xru6oNFwV9nGkClLB6jQ)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain] [1.14s] Chain run errored with error:\n",
      "\u001b[0m\"BadRequestError('(Request ID: 6xru6oNFwV9nGkClLB6jQ)\\\\n\\\\nBad request:\\\\nAuthorization header is correct, but the token seems invalid')Traceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 406, in hf_raise_for_status\\n    response.raise_for_status()\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\requests\\\\models.py\\\", line 1024, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\n\\n\\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2\\n\\n\\n\\nThe above exception was the direct cause of the following exception:\\n\\n\\n\\nTraceback (most recent call last):\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py\\\", line 160, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\qa_with_sources\\\\base.py\\\", line 166, in _call\\n    answer = self.combine_documents_chain.run(\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py\\\", line 182, in warning_emitting_wrapper\\n    return wrapped(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py\\\", line 611, in run\\n    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\_api\\\\deprecation.py\\\", line 182, in warning_emitting_wrapper\\n    return wrapped(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py\\\", line 389, in __call__\\n    return self.invoke(\\n           ^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py\\\", line 170, in invoke\\n    raise e\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\base.py\\\", line 160, in invoke\\n    self._call(inputs, run_manager=run_manager)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\combine_documents\\\\base.py\\\", line 138, in _call\\n    output, extra_return_dict = self.combine_docs(\\n                                ^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\combine_documents\\\\map_reduce.py\\\", line 240, in combine_docs\\n    map_results = self.llm_chain.apply(\\n                  ^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\llm.py\\\", line 251, in apply\\n    raise e\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\llm.py\\\", line 248, in apply\\n    response = self.generate(input_list, run_manager=run_manager)\\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain\\\\chains\\\\llm.py\\\", line 138, in generate\\n    return self.llm.generate_prompt(\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 755, in generate_prompt\\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 950, in generate\\n    output = self._generate_helper(\\n             ^^^^^^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 792, in _generate_helper\\n    raise e\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 779, in _generate_helper\\n    self._generate(\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_core\\\\language_models\\\\llms.py\\\", line 1502, in _generate\\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\langchain_community\\\\llms\\\\huggingface_hub.py\\\", line 138, in _call\\n    response = self.client.post(\\n               ^^^^^^^^^^^^^^^^^\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\inference\\\\_client.py\\\", line 305, in post\\n    hf_raise_for_status(response)\\n\\n\\n  File \\\"c:\\\\Users\\\\Khyati\\\\anaconda3\\\\Lib\\\\site-packages\\\\huggingface_hub\\\\utils\\\\_http.py\\\", line 460, in hf_raise_for_status\\n    raise _format(BadRequestError, message, response) from e\\n\\n\\nhuggingface_hub.errors.BadRequestError: (Request ID: 6xru6oNFwV9nGkClLB6jQ)\\n\\nBad request:\\nAuthorization header is correct, but the token seems invalid\"\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "(Request ID: 6xru6oNFwV9nGkClLB6jQ)\n\nBad request:\nAuthorization header is correct, but the token seems invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is the price of tiago iCNG\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m langchain\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m chain({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: query}, return_only_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    390\u001b[0m     inputs,\n\u001b[0;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    392\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    393\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    394\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\qa_with_sources\\base.py:166\u001b[0m, in \u001b[0;36mBaseQAWithSourcesChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(inputs)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_documents_chain\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    167\u001b[0m     input_documents\u001b[38;5;241m=\u001b[39mdocs, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs\n\u001b[0;32m    168\u001b[0m )\n\u001b[0;32m    169\u001b[0m answer, sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_sources(answer)\n\u001b[0;32m    170\u001b[0m result: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manswer_key: answer,\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msources_answer_key: sources,\n\u001b[0;32m    173\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:611\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     emit_warning()\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m    390\u001b[0m     inputs,\n\u001b[0;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[0;32m    392\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[0;32m    393\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[0;32m    394\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\combine_documents\\base.py:138\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[0;32m    137\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[1;32m--> 138\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_docs(\n\u001b[0;32m    139\u001b[0m     docs, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother_keys\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    141\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\combine_documents\\map_reduce.py:240\u001b[0m, in \u001b[0;36mMapReduceDocumentsChain.combine_docs\u001b[1;34m(self, docs, token_max, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_docs\u001b[39m(\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    230\u001b[0m     docs: List[Document],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    234\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Combine documents in a map reduce manner.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m    Combine by mapping first chain over all documents, then reducing the results.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m    This reducing can be done recursively if needed (if there are many documents).\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     map_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# FYI - this is parallelized and so it is fast.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m         [{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocument_variable_name: d\u001b[38;5;241m.\u001b[39mpage_content, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs} \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs],\n\u001b[0;32m    243\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    245\u001b[0m     question_result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39moutput_key\n\u001b[0;32m    246\u001b[0m     result_docs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    247\u001b[0m         Document(page_content\u001b[38;5;241m=\u001b[39mr[question_result_key], metadata\u001b[38;5;241m=\u001b[39mdocs[i]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m    248\u001b[0m         \u001b[38;5;66;03m# This uses metadata from the docs, and the textual results from `results`\u001b[39;00m\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(map_results)\n\u001b[0;32m    250\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:251\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list, callbacks)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    250\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    252\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)\n\u001b[0;32m    253\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs})\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:248\u001b[0m, in \u001b[0;36mLLMChain.apply\u001b[1;34m(self, input_list, callbacks)\u001b[0m\n\u001b[0;32m    242\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    244\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_list\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_list},\n\u001b[0;32m    245\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_name(),\n\u001b[0;32m    246\u001b[0m )\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(input_list, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    250\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain\\chains\\llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    139\u001b[0m         prompts,\n\u001b[0;32m    140\u001b[0m         stop,\n\u001b[0;32m    141\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:755\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    749\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    753\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    754\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m         )\n\u001b[0;32m    949\u001b[0m     ]\n\u001b[1;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    951\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    952\u001b[0m     )\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[0;32m    791\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 792\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    793\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:779\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    771\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    776\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    778\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 779\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    780\u001b[0m                 prompts,\n\u001b[0;32m    781\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    782\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    783\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    784\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    785\u001b[0m             )\n\u001b[0;32m    786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    787\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    788\u001b[0m         )\n\u001b[0;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1502\u001b[0m, in \u001b[0;36mLLM._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m   1501\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1502\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1503\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m   1504\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1505\u001b[0m     )\n\u001b[0;32m   1506\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\langchain_community\\llms\\huggingface_hub.py:138\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[1;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m _model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    136\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 138\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m    139\u001b[0m     json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: parameters}, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask\n\u001b[0;32m    140\u001b[0m )\n\u001b[0;32m    141\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:305\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[1;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 305\u001b[0m     hf_raise_for_status(response)\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32mc:\\Users\\Khyati\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:460\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m    457\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m     )\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(BadRequestError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m    463\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure your token has the correct permissions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    467\u001b[0m     )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: (Request ID: 6xru6oNFwV9nGkClLB6jQ)\n\nBad request:\nAuthorization header is correct, but the token seems invalid"
     ]
    }
   ],
   "source": [
    "query = \"what is the price of tiago iCNG\"\n",
    "\n",
    "langchain.debug = True\n",
    "\n",
    "chain({\"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
